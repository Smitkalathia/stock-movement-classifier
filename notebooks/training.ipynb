{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "287efc61",
   "metadata": {},
   "source": [
    "# Stock Movement Prediction – Training Notebook\n",
    "This notebook downloads stock data, builds 20‑day windows, trains MLP and LSTM models, evaluates accuracy, and saves weights for deployment."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ad6bf70",
   "metadata": {},
   "source": [
    "## 1. Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "22a51b58",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cpu')"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import yfinance as yf\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "import os\n",
    "\n",
    "SEED=42\n",
    "np.random.seed(SEED)\n",
    "torch.manual_seed(SEED)\n",
    "device=torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "device"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b900df1",
   "metadata": {},
   "source": [
    "## 2. Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "8f40d851",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['AAPL', 'MSFT', 'AMZN', 'GOOGL', 'META', 'TSLA', 'SPY']"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TICKERS=[\"AAPL\",\"MSFT\",\"AMZN\",\"GOOGL\",\"META\",\"TSLA\",\"SPY\"]\n",
    "START_DATE=\"2015-01-01\"\n",
    "END_DATE=\"2024-12-31\"\n",
    "WINDOW_SIZE=20\n",
    "BATCH_SIZE=64\n",
    "EPOCHS_MLP=15\n",
    "EPOCHS_LSTM=15\n",
    "LR=1e-3\n",
    "\n",
    "TICKERS"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3d339d5",
   "metadata": {},
   "source": [
    "## 3. Download Data\n",
    "We fetch daily OHLCV stock prices using yfinance, compute daily returns, and generate labels (1 = next‑day price up)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "08008b40",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Downloading AAPL...\n",
      "✅ Loaded AAPL, rows: 2514\n",
      "\n",
      "Downloading MSFT...\n",
      "✅ Loaded MSFT, rows: 2514\n",
      "\n",
      "Downloading AMZN...\n",
      "✅ Loaded AMZN, rows: 2514\n",
      "\n",
      "Downloading GOOGL...\n",
      "✅ Loaded GOOGL, rows: 2514\n",
      "\n",
      "Downloading META...\n",
      "✅ Loaded META, rows: 2514\n",
      "\n",
      "Downloading TSLA...\n",
      "✅ Loaded TSLA, rows: 2514\n",
      "\n",
      "Downloading SPY...\n",
      "✅ Loaded SPY, rows: 2514\n",
      "Final dataset size: (17598, 9)\n",
      "\n",
      "Final tickers used: ['AAPL', 'MSFT', 'AMZN', 'GOOGL', 'META', 'TSLA', 'SPY']\n"
     ]
    }
   ],
   "source": [
    "all_frames = []\n",
    "\n",
    "for ticker in TICKERS:\n",
    "    print(f\"\\nDownloading {ticker}...\")\n",
    "\n",
    "    df = yf.download(\n",
    "        ticker,\n",
    "        start=START_DATE,\n",
    "        end=END_DATE,\n",
    "        progress=False,\n",
    "        auto_adjust=False,\n",
    "        group_by=None\n",
    "    )\n",
    "\n",
    "    if df is None or df.empty:\n",
    "        print(f\"❌ Skipping {ticker} (empty DataFrame)\")\n",
    "        continue\n",
    "\n",
    "    # Your MultiIndex fix:\n",
    "    df.columns = df.columns.droplevel(0)\n",
    "\n",
    "    if \"Close\" not in df.columns:\n",
    "        print(f\"❌ Skipping {ticker} (missing Close)\")\n",
    "        print(df.columns)\n",
    "        continue\n",
    "\n",
    "    df = df.sort_index()\n",
    "    df[\"Return\"] = df[\"Close\"].pct_change()\n",
    "    df[\"Target\"] = (df[\"Return\"].shift(-1) > 0).astype(int)\n",
    "    df[\"Ticker\"] = ticker\n",
    "\n",
    "    df = df.dropna(subset=[\"Return\", \"Target\"])\n",
    "\n",
    "    if df.empty:\n",
    "        print(f\"❌ Skipping {ticker} (no valid rows after cleaning)\")\n",
    "        continue\n",
    "\n",
    "    print(f\"✅ Loaded {ticker}, rows:\", len(df))\n",
    "    all_frames.append(df)\n",
    "data = pd.concat(all_frames)\n",
    "print(\"Final dataset size:\", data.shape)\n",
    "data.head()\n",
    "\n",
    "print(\"\\nFinal tickers used:\", [df[\"Ticker\"].iloc[0] for df in all_frames])\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a03e966",
   "metadata": {},
   "source": [
    "## 4. Build Sliding Windows\n",
    "Each sample consists of the last 20 daily returns → label is next day's movement."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "f388f193",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((17458, 20), (17458,))"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_list=[]; y_list=[]\n",
    "for ticker in TICKERS:\n",
    "    df=data[data['Ticker']==ticker].sort_index()\n",
    "    ret=df['Return'].values\n",
    "    tgt=df['Target'].values\n",
    "    for i in range(WINDOW_SIZE,len(df)):\n",
    "        X_list.append(ret[i-WINDOW_SIZE:i])\n",
    "        y_list.append(tgt[i-1])\n",
    "\n",
    "X=np.array(X_list,dtype=np.float32)\n",
    "y=np.array(y_list,dtype=np.float32)\n",
    "X.shape, y.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a6fcf90",
   "metadata": {},
   "source": [
    "## 5. Train/Val/Test Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "a9582ede",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((12220, 20), (2619, 20), (2619, 20))"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n=len(X)\n",
    "train_end=int(0.7*n)\n",
    "val_end=int(0.85*n)\n",
    "\n",
    "X_train, y_train = X[:train_end], y[:train_end]\n",
    "X_val, y_val = X[train_end:val_end], y[train_end:val_end]\n",
    "X_test, y_test = X[val_end:], y[val_end:]\n",
    "\n",
    "X_train.shape, X_val.shape, X_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa48a55a",
   "metadata": {},
   "source": [
    "## 6. Create Torch Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "e493a850",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_t=torch.tensor(X_train)\n",
    "y_train_t=torch.tensor(y_train.reshape(-1,1))\n",
    "X_val_t=torch.tensor(X_val)\n",
    "y_val_t=torch.tensor(y_val.reshape(-1,1))\n",
    "X_test_t=torch.tensor(X_test)\n",
    "y_test_t=torch.tensor(y_test.reshape(-1,1))\n",
    "\n",
    "train_loader=DataLoader(TensorDataset(X_train_t,y_train_t),batch_size=BATCH_SIZE,shuffle=True)\n",
    "val_loader=DataLoader(TensorDataset(X_val_t,y_val_t),batch_size=BATCH_SIZE)\n",
    "test_loader=DataLoader(TensorDataset(X_test_t,y_test_t),batch_size=BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "158e94ee",
   "metadata": {},
   "source": [
    "## 7. Define MLP and LSTM Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "8b5e4b02",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MLPClassifier(nn.Module):\n",
    "    def __init__(self, input_dim):\n",
    "        super().__init__()\n",
    "        self.net=nn.Sequential(\n",
    "            nn.Linear(input_dim,128),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.2),\n",
    "            nn.Linear(128,64),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(64,1),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "    def forward(self,x): return self.net(x.float())\n",
    "\n",
    "class LSTMClassifier(nn.Module):\n",
    "    def __init__(self, feature_dim, hidden_size=64, num_layers=1):\n",
    "        super().__init__()\n",
    "        self.lstm=nn.LSTM(feature_dim,hidden_size,num_layers,batch_first=True)\n",
    "        self.fc=nn.Linear(hidden_size,1)\n",
    "        self.sigmoid=nn.Sigmoid()\n",
    "    def forward(self,x):\n",
    "        out,_=self.lstm(x.float())\n",
    "        out=self.fc(out[:,-1,:])\n",
    "        return self.sigmoid(out)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "270f02de",
   "metadata": {},
   "source": [
    "## 8. Training Helpers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "0dc108ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_epoch(model,loader,crit,opt):\n",
    "    model.train(); total=correct=loss_sum=0\n",
    "    for xb,yb in loader:\n",
    "        xb, yb = xb.to(device), yb.to(device)\n",
    "        opt.zero_grad()\n",
    "        pred=model(xb)\n",
    "        loss=crit(pred,yb)\n",
    "        loss.backward()\n",
    "        opt.step()\n",
    "        loss_sum+=loss.item()*len(xb)\n",
    "        correct+=((pred>=0.5).float()==yb).sum().item()\n",
    "        total+=len(xb)\n",
    "    return loss_sum/total, correct/total\n",
    "\n",
    "def eval_epoch(model,loader,crit):\n",
    "    model.eval(); total=correct=loss_sum=0; preds=[]; labels=[]\n",
    "    with torch.no_grad():\n",
    "        for xb,yb in loader:\n",
    "            xb,yb=xb.to(device),yb.to(device)\n",
    "            pred=model(xb)\n",
    "            loss=crit(pred,yb)\n",
    "            loss_sum+=loss.item()*len(xb)\n",
    "            correct+=((pred>=0.5).float()==yb).sum().item()\n",
    "            total+=len(xb)\n",
    "            preds.extend((pred>=0.5).cpu().numpy().astype(int))\n",
    "            labels.extend(yb.cpu().numpy().astype(int))\n",
    "    return loss_sum/total, correct/total, preds, labels"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7866639f",
   "metadata": {},
   "source": [
    "## 9. Train MLP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "4944d555",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MLP 1: Train 0.6916/0.5281, Val 0.6926/0.5193\n",
      "MLP 2: Train 0.6910/0.5326, Val 0.6928/0.5193\n",
      "MLP 3: Train 0.6906/0.5327, Val 0.6935/0.5193\n",
      "MLP 4: Train 0.6908/0.5336, Val 0.6922/0.5204\n",
      "MLP 5: Train 0.6898/0.5360, Val 0.6922/0.5132\n",
      "MLP 6: Train 0.6895/0.5322, Val 0.6926/0.5059\n",
      "MLP 7: Train 0.6898/0.5307, Val 0.6923/0.5078\n",
      "MLP 8: Train 0.6889/0.5381, Val 0.6929/0.5078\n",
      "MLP 9: Train 0.6884/0.5358, Val 0.6953/0.5128\n",
      "MLP 10: Train 0.6886/0.5345, Val 0.6961/0.5116\n",
      "MLP 11: Train 0.6882/0.5385, Val 0.6960/0.5139\n",
      "MLP 12: Train 0.6871/0.5403, Val 0.6967/0.5094\n",
      "MLP 13: Train 0.6871/0.5421, Val 0.6965/0.5128\n",
      "MLP 14: Train 0.6870/0.5434, Val 0.6954/0.5101\n",
      "MLP 15: Train 0.6861/0.5419, Val 0.6969/0.5136\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mlp=MLPClassifier(WINDOW_SIZE).to(device)\n",
    "crit=nn.BCELoss()\n",
    "opt=torch.optim.Adam(mlp.parameters(),lr=LR)\n",
    "best=None; best_val=float(\"inf\")\n",
    "\n",
    "for epoch in range(1,EPOCHS_MLP+1):\n",
    "    tr_l,tr_a=train_epoch(mlp,train_loader,crit,opt)\n",
    "    va_l,va_a,_,_=eval_epoch(mlp,val_loader,crit)\n",
    "    print(f\"MLP {epoch}: Train {tr_l:.4f}/{tr_a:.4f}, Val {va_l:.4f}/{va_a:.4f}\")\n",
    "    if va_l<best_val: best_val=va_l; best=mlp.state_dict()\n",
    "\n",
    "mlp.load_state_dict(best)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52d1d456",
   "metadata": {},
   "source": [
    "## 10. Test MLP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "d8fc4662",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MLP Test Accuracy: 0.5421916762122948\n"
     ]
    }
   ],
   "source": [
    "tl,ta,preds,labels=eval_epoch(mlp,test_loader,crit)\n",
    "print(\"MLP Test Accuracy:\", ta)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22fb5f79",
   "metadata": {},
   "source": [
    "## 11. Prepare LSTM Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "a14a63fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_seq=X_train.reshape(-1,WINDOW_SIZE,1)\n",
    "X_val_seq=X_val.reshape(-1,WINDOW_SIZE,1)\n",
    "X_test_seq=X_test.reshape(-1,WINDOW_SIZE,1)\n",
    "\n",
    "train_loader_seq=DataLoader(TensorDataset(torch.tensor(X_train_seq),y_train_t),batch_size=BATCH_SIZE,shuffle=True)\n",
    "val_loader_seq=DataLoader(TensorDataset(torch.tensor(X_val_seq),y_val_t),batch_size=BATCH_SIZE)\n",
    "test_loader_seq=DataLoader(TensorDataset(torch.tensor(X_test_seq),y_test_t),batch_size=BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c801d8e",
   "metadata": {},
   "source": [
    "## 12. Train LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "ed0993b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LSTM 1: Train 0.6917/0.5273, Val 0.6924/0.5193\n",
      "LSTM 2: Train 0.6912/0.5326, Val 0.6927/0.5193\n",
      "LSTM 3: Train 0.6911/0.5326, Val 0.6929/0.5193\n",
      "LSTM 4: Train 0.6913/0.5326, Val 0.6928/0.5193\n",
      "LSTM 5: Train 0.6911/0.5326, Val 0.6923/0.5193\n",
      "LSTM 6: Train 0.6911/0.5326, Val 0.6933/0.5193\n",
      "LSTM 7: Train 0.6911/0.5326, Val 0.6926/0.5193\n",
      "LSTM 8: Train 0.6910/0.5326, Val 0.6923/0.5193\n",
      "LSTM 9: Train 0.6910/0.5326, Val 0.6922/0.5193\n",
      "LSTM 10: Train 0.6911/0.5326, Val 0.6923/0.5193\n",
      "LSTM 11: Train 0.6910/0.5327, Val 0.6933/0.5193\n",
      "LSTM 12: Train 0.6910/0.5327, Val 0.6928/0.5193\n",
      "LSTM 13: Train 0.6910/0.5326, Val 0.6925/0.5193\n",
      "LSTM 14: Train 0.6910/0.5327, Val 0.6929/0.5189\n",
      "LSTM 15: Train 0.6910/0.5327, Val 0.6925/0.5193\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lstm=LSTMClassifier(feature_dim=1).to(device)\n",
    "opt2=torch.optim.Adam(lstm.parameters(),lr=LR)\n",
    "best_l=None; best_val_l=float(\"inf\")\n",
    "\n",
    "for epoch in range(1,EPOCHS_LSTM+1):\n",
    "    tr_l,tr_a=train_epoch(lstm,train_loader_seq,crit,opt2)\n",
    "    va_l,va_a,_,_=eval_epoch(lstm,val_loader_seq,crit)\n",
    "    print(f\"LSTM {epoch}: Train {tr_l:.4f}/{tr_a:.4f}, Val {va_l:.4f}/{va_a:.4f}\")\n",
    "    if va_l<best_val_l: best_val_l=va_l; best_l=lstm.state_dict()\n",
    "\n",
    "lstm.load_state_dict(best_l)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a6944a3",
   "metadata": {},
   "source": [
    "## 13. Test LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "b77715cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LSTM Test Accuracy: 0.5441008018327605\n"
     ]
    }
   ],
   "source": [
    "tl,ta,preds,labels=eval_epoch(lstm,test_loader_seq,crit)\n",
    "print(\"LSTM Test Accuracy:\", ta)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc86eea2",
   "metadata": {},
   "source": [
    "## 14. Save Weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "454db72a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved mlp_weights.pth and lstm_weights.pth\n"
     ]
    }
   ],
   "source": [
    "os.makedirs(\"../models/saved_weights\",exist_ok=True)\n",
    "torch.save(mlp.state_dict(),\"../models/saved_weights/mlp_weights.pth\")\n",
    "torch.save(lstm.state_dict(),\"../models/saved_weights/lstm_weights.pth\")\n",
    "print(\"Saved mlp_weights.pth and lstm_weights.pth\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
