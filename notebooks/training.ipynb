{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "287efc61",
   "metadata": {},
   "source": [
    "# Stock Movement Prediction – Training Notebook\n",
    "This notebook downloads stock data, builds 20‑day windows, trains MLP and LSTM models, evaluates accuracy, and saves weights for deployment."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ad6bf70",
   "metadata": {},
   "source": [
    "## 1. Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "22a51b58",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cpu')"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import yfinance as yf\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "import os\n",
    "from datetime import datetime, timedelta\n",
    "\n",
    "SEED=42\n",
    "np.random.seed(SEED)\n",
    "torch.manual_seed(SEED)\n",
    "device=torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "device"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b900df1",
   "metadata": {},
   "source": [
    "## 2. Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f40d851",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total tickers loaded: 50\n",
      "Tickers: ['ABT', 'ABBV', 'ACN', 'ADBE', 'AMD', 'GOOGL', 'GOOG', 'AMZN', 'AAPL', 'BAC', 'BRK-B', 'AVGO', 'CVX', 'CSCO', 'KO', 'CMCSA', 'COST', 'DHR', 'XOM', 'HD', 'INTC', 'JNJ', 'JPM', 'LLY', 'LIN', 'MA', 'MCD', 'MRK', 'META', 'MSFT', 'NEE', 'NKE', 'NVDA', 'ORCL', 'PEP', 'PFE', 'PM', 'PG', 'RTX', 'CRM', 'TSLA', 'TXN', 'TMO', 'UPS', 'UNH', 'VZ', 'V', 'WMT', 'DIS', 'WFC']\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Load S&P 500 constituents list\n",
    "url = \"https://raw.githubusercontent.com/datasets/s-and-p-500-companies/master/data/constituents.csv\"\n",
    "sp500 = pd.read_csv(url)\n",
    "\n",
    "# Clean tickers: replace '.' with '-' for yfinance compatibility\n",
    "sp500['Symbol'] = sp500['Symbol'].str.replace('.', '-', regex=False)\n",
    "\n",
    "# Hardcoded So users can easily add and remove specific tickers according to preferences\n",
    "TOP50 = [\n",
    "    \"AAPL\", \"MSFT\", \"AMZN\", \"NVDA\", \"GOOGL\", \"GOOG\", \"META\", \"TSLA\", \"BRK-B\", \"UNH\",\n",
    "    \"XOM\", \"JPM\", \"JNJ\", \"V\", \"PG\", \"LLY\", \"HD\", \"MA\", \"CVX\", \"AVGO\",\n",
    "    \"COST\", \"PEP\", \"PFE\", \"KO\", \"MRK\", \"ABBV\", \"WMT\", \"BAC\", \"TMO\", \"DIS\",\n",
    "    \"ADBE\", \"CSCO\", \"CRM\", \"MCD\", \"ACN\", \"LIN\", \"ABT\", \"ORCL\", \"NKE\", \"DHR\",\n",
    "    \"CMCSA\", \"TXN\", \"NEE\", \"WFC\", \"PM\", \"VZ\", \"RTX\", \"UPS\", \"INTC\", \"AMD\"\n",
    "]\n",
    "\n",
    "# Filter the S&P 500 tickers to only include those in our TOP50 list\n",
    "TICKERS = [t for t in sp500['Symbol'].tolist() if t in TOP50]\n",
    "\n",
    "print(\"Total tickers loaded:\", len(TICKERS))\n",
    "print(\"Tickers:\", TICKERS)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3d339d5",
   "metadata": {},
   "source": [
    "## 3. Download Data\n",
    "We fetch daily OHLCV stock prices using yfinance, compute daily returns, and generate labels (1 = next‑day price up)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "08008b40",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "START_DATE: 2018-12-09\n",
      "END_DATE: 2025-12-07\n",
      "\n",
      "Downloading ABT...\n",
      "✅ Loaded ABT, rows: 1757\n",
      "\n",
      "Downloading ABBV...\n",
      "✅ Loaded ABBV, rows: 1757\n",
      "\n",
      "Downloading ACN...\n",
      "✅ Loaded ACN, rows: 1757\n",
      "\n",
      "Downloading ADBE...\n",
      "✅ Loaded ADBE, rows: 1757\n",
      "\n",
      "Downloading AMD...\n",
      "✅ Loaded AMD, rows: 1757\n",
      "\n",
      "Downloading GOOGL...\n",
      "✅ Loaded GOOGL, rows: 1757\n",
      "\n",
      "Downloading GOOG...\n",
      "✅ Loaded GOOG, rows: 1757\n",
      "\n",
      "Downloading AMZN...\n",
      "✅ Loaded AMZN, rows: 1757\n",
      "\n",
      "Downloading AAPL...\n",
      "✅ Loaded AAPL, rows: 1757\n",
      "\n",
      "Downloading BAC...\n",
      "✅ Loaded BAC, rows: 1757\n",
      "\n",
      "Downloading BRK-B...\n",
      "✅ Loaded BRK-B, rows: 1757\n",
      "\n",
      "Downloading AVGO...\n",
      "✅ Loaded AVGO, rows: 1757\n",
      "\n",
      "Downloading CVX...\n",
      "✅ Loaded CVX, rows: 1757\n",
      "\n",
      "Downloading CSCO...\n",
      "✅ Loaded CSCO, rows: 1757\n",
      "\n",
      "Downloading KO...\n",
      "✅ Loaded KO, rows: 1757\n",
      "\n",
      "Downloading CMCSA...\n",
      "✅ Loaded CMCSA, rows: 1757\n",
      "\n",
      "Downloading COST...\n",
      "✅ Loaded COST, rows: 1757\n",
      "\n",
      "Downloading DHR...\n",
      "✅ Loaded DHR, rows: 1757\n",
      "\n",
      "Downloading XOM...\n",
      "✅ Loaded XOM, rows: 1757\n",
      "\n",
      "Downloading HD...\n",
      "✅ Loaded HD, rows: 1757\n",
      "\n",
      "Downloading INTC...\n",
      "✅ Loaded INTC, rows: 1757\n",
      "\n",
      "Downloading JNJ...\n",
      "✅ Loaded JNJ, rows: 1757\n",
      "\n",
      "Downloading JPM...\n",
      "✅ Loaded JPM, rows: 1757\n",
      "\n",
      "Downloading LLY...\n",
      "✅ Loaded LLY, rows: 1757\n",
      "\n",
      "Downloading LIN...\n",
      "✅ Loaded LIN, rows: 1757\n",
      "\n",
      "Downloading MA...\n",
      "✅ Loaded MA, rows: 1757\n",
      "\n",
      "Downloading MCD...\n",
      "✅ Loaded MCD, rows: 1757\n",
      "\n",
      "Downloading MRK...\n",
      "✅ Loaded MRK, rows: 1757\n",
      "\n",
      "Downloading META...\n",
      "✅ Loaded META, rows: 1757\n",
      "\n",
      "Downloading MSFT...\n",
      "✅ Loaded MSFT, rows: 1757\n",
      "\n",
      "Downloading NEE...\n",
      "✅ Loaded NEE, rows: 1757\n",
      "\n",
      "Downloading NKE...\n",
      "✅ Loaded NKE, rows: 1757\n",
      "\n",
      "Downloading NVDA...\n",
      "✅ Loaded NVDA, rows: 1757\n",
      "\n",
      "Downloading ORCL...\n",
      "✅ Loaded ORCL, rows: 1757\n",
      "\n",
      "Downloading PEP...\n",
      "✅ Loaded PEP, rows: 1757\n",
      "\n",
      "Downloading PFE...\n",
      "✅ Loaded PFE, rows: 1757\n",
      "\n",
      "Downloading PM...\n",
      "✅ Loaded PM, rows: 1757\n",
      "\n",
      "Downloading PG...\n",
      "✅ Loaded PG, rows: 1757\n",
      "\n",
      "Downloading RTX...\n",
      "✅ Loaded RTX, rows: 1757\n",
      "\n",
      "Downloading CRM...\n",
      "✅ Loaded CRM, rows: 1757\n",
      "\n",
      "Downloading TSLA...\n",
      "✅ Loaded TSLA, rows: 1757\n",
      "\n",
      "Downloading TXN...\n",
      "✅ Loaded TXN, rows: 1757\n",
      "\n",
      "Downloading TMO...\n",
      "✅ Loaded TMO, rows: 1757\n",
      "\n",
      "Downloading UPS...\n",
      "✅ Loaded UPS, rows: 1757\n",
      "\n",
      "Downloading UNH...\n",
      "✅ Loaded UNH, rows: 1757\n",
      "\n",
      "Downloading VZ...\n",
      "✅ Loaded VZ, rows: 1757\n",
      "\n",
      "Downloading V...\n",
      "✅ Loaded V, rows: 1757\n",
      "\n",
      "Downloading WMT...\n",
      "✅ Loaded WMT, rows: 1757\n",
      "\n",
      "Downloading DIS...\n",
      "✅ Loaded DIS, rows: 1757\n",
      "\n",
      "Downloading WFC...\n",
      "✅ Loaded WFC, rows: 1757\n",
      "Final dataset size: (87850, 9)\n",
      "\n",
      "Final tickers used: ['ABT', 'ABBV', 'ACN', 'ADBE', 'AMD', 'GOOGL', 'GOOG', 'AMZN', 'AAPL', 'BAC', 'BRK-B', 'AVGO', 'CVX', 'CSCO', 'KO', 'CMCSA', 'COST', 'DHR', 'XOM', 'HD', 'INTC', 'JNJ', 'JPM', 'LLY', 'LIN', 'MA', 'MCD', 'MRK', 'META', 'MSFT', 'NEE', 'NKE', 'NVDA', 'ORCL', 'PEP', 'PFE', 'PM', 'PG', 'RTX', 'CRM', 'TSLA', 'TXN', 'TMO', 'UPS', 'UNH', 'VZ', 'V', 'WMT', 'DIS', 'WFC']\n"
     ]
    }
   ],
   "source": [
    "# End date = today\n",
    "END_DATE = datetime.today().strftime(\"%Y-%m-%d\")\n",
    "\n",
    "# Start date = 7 years before today\n",
    "START_DATE = (datetime.today() - timedelta(days=365*7)).strftime(\"%Y-%m-%d\")\n",
    "\n",
    "print(\"START_DATE:\", START_DATE)\n",
    "print(\"END_DATE:\", END_DATE)\n",
    "\n",
    "all_frames = []\n",
    "for ticker in TICKERS:\n",
    "    print(f\"\\nDownloading {ticker}...\")\n",
    "\n",
    "    df = yf.download(\n",
    "        ticker,\n",
    "        start=START_DATE,\n",
    "        end=END_DATE,\n",
    "        progress=False,\n",
    "        auto_adjust=False,\n",
    "        group_by=None\n",
    "    )\n",
    "\n",
    "    if df is None or df.empty:\n",
    "        print(f\"❌ Skipping {ticker} (empty DataFrame)\")\n",
    "        continue\n",
    "\n",
    "    # Your MultiIndex fix:\n",
    "    df.columns = df.columns.droplevel(0)\n",
    "\n",
    "    if \"Close\" not in df.columns:\n",
    "        print(f\"❌ Skipping {ticker} (missing Close)\")\n",
    "        print(df.columns)\n",
    "        continue\n",
    "\n",
    "    df = df.sort_index()\n",
    "    df[\"Return\"] = df[\"Close\"].pct_change()\n",
    "    df[\"Target\"] = (df[\"Return\"].shift(-1) > 0).astype(int)\n",
    "    df[\"Ticker\"] = ticker\n",
    "\n",
    "    df = df.dropna(subset=[\"Return\", \"Target\"])\n",
    "\n",
    "    if df.empty:\n",
    "        print(f\"❌ Skipping {ticker} (no valid rows after cleaning)\")\n",
    "        continue\n",
    "\n",
    "    print(f\"✅ Loaded {ticker}, rows:\", len(df))\n",
    "    all_frames.append(df)\n",
    "data = pd.concat(all_frames)\n",
    "print(\"Final dataset size:\", data.shape)\n",
    "data.head()\n",
    "\n",
    "print(\"\\nFinal tickers used:\", [df[\"Ticker\"].iloc[0] for df in all_frames])\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a03e966",
   "metadata": {},
   "source": [
    "## 4. Build Sliding Windows\n",
    "Each sample consists of the last 20 daily returns → label is next day's movement."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "f388f193",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((86850, 20), (86850,))"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_list=[]; y_list=[]\n",
    "for ticker in TICKERS:\n",
    "    df=data[data['Ticker']==ticker].sort_index()\n",
    "    ret=df['Return'].values\n",
    "    tgt=df['Target'].values\n",
    "    for i in range(WINDOW_SIZE,len(df)):\n",
    "        X_list.append(ret[i-WINDOW_SIZE:i])\n",
    "        y_list.append(tgt[i-1])\n",
    "\n",
    "X=np.array(X_list,dtype=np.float32)\n",
    "y=np.array(y_list,dtype=np.float32)\n",
    "X.shape, y.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a6fcf90",
   "metadata": {},
   "source": [
    "## 5. Train/Val/Test Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "a9582ede",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((60794, 20), (13028, 20), (13028, 20))"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n=len(X)\n",
    "train_end=int(0.7*n)\n",
    "val_end=int(0.85*n)\n",
    "\n",
    "X_train, y_train = X[:train_end], y[:train_end]\n",
    "X_val, y_val = X[train_end:val_end], y[train_end:val_end]\n",
    "X_test, y_test = X[val_end:], y[val_end:]\n",
    "\n",
    "X_train.shape, X_val.shape, X_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa48a55a",
   "metadata": {},
   "source": [
    "## 6. Create Torch Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "e493a850",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_t=torch.tensor(X_train)\n",
    "y_train_t=torch.tensor(y_train.reshape(-1,1))\n",
    "X_val_t=torch.tensor(X_val)\n",
    "y_val_t=torch.tensor(y_val.reshape(-1,1))\n",
    "X_test_t=torch.tensor(X_test)\n",
    "y_test_t=torch.tensor(y_test.reshape(-1,1))\n",
    "\n",
    "train_loader=DataLoader(TensorDataset(X_train_t,y_train_t),batch_size=BATCH_SIZE,shuffle=True)\n",
    "val_loader=DataLoader(TensorDataset(X_val_t,y_val_t),batch_size=BATCH_SIZE)\n",
    "test_loader=DataLoader(TensorDataset(X_test_t,y_test_t),batch_size=BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "158e94ee",
   "metadata": {},
   "source": [
    "## 7. Define MLP and LSTM Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "8b5e4b02",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MLPClassifier(nn.Module):\n",
    "    def __init__(self, input_dim):\n",
    "        super().__init__()\n",
    "        self.net=nn.Sequential(\n",
    "            nn.Linear(input_dim,128),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.2),\n",
    "            nn.Linear(128,64),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(64,1),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "    def forward(self,x): return self.net(x.float())\n",
    "\n",
    "class LSTMClassifier(nn.Module):\n",
    "    def __init__(self, feature_dim, hidden_size=64, num_layers=1):\n",
    "        super().__init__()\n",
    "        self.lstm=nn.LSTM(feature_dim,hidden_size,num_layers,batch_first=True)\n",
    "        self.fc=nn.Linear(hidden_size,1)\n",
    "        self.sigmoid=nn.Sigmoid()\n",
    "    def forward(self,x):\n",
    "        out,_=self.lstm(x.float())\n",
    "        out=self.fc(out[:,-1,:])\n",
    "        return self.sigmoid(out)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "270f02de",
   "metadata": {},
   "source": [
    "## 8. Training Helpers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "0dc108ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_epoch(model,loader,crit,opt):\n",
    "    model.train(); total=correct=loss_sum=0\n",
    "    for xb,yb in loader:\n",
    "        xb, yb = xb.to(device), yb.to(device)\n",
    "        opt.zero_grad()\n",
    "        pred=model(xb)\n",
    "        loss=crit(pred,yb)\n",
    "        loss.backward()\n",
    "        opt.step()\n",
    "        loss_sum+=loss.item()*len(xb)\n",
    "        correct+=((pred>=0.5).float()==yb).sum().item()\n",
    "        total+=len(xb)\n",
    "    return loss_sum/total, correct/total\n",
    "\n",
    "def eval_epoch(model,loader,crit):\n",
    "    model.eval(); total=correct=loss_sum=0; preds=[]; labels=[]\n",
    "    with torch.no_grad():\n",
    "        for xb,yb in loader:\n",
    "            xb,yb=xb.to(device),yb.to(device)\n",
    "            pred=model(xb)\n",
    "            loss=crit(pred,yb)\n",
    "            loss_sum+=loss.item()*len(xb)\n",
    "            correct+=((pred>=0.5).float()==yb).sum().item()\n",
    "            total+=len(xb)\n",
    "            preds.extend((pred>=0.5).cpu().numpy().astype(int))\n",
    "            labels.extend(yb.cpu().numpy().astype(int))\n",
    "    return loss_sum/total, correct/total, preds, labels"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7866639f",
   "metadata": {},
   "source": [
    "## 9. Train MLP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "4944d555",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MLP 1: Train 0.6916/0.5261, Val 0.6909/0.5319\n",
      "MLP 2: Train 0.6905/0.5292, Val 0.6901/0.5325\n",
      "MLP 3: Train 0.6893/0.5325, Val 0.6900/0.5305\n",
      "MLP 4: Train 0.6885/0.5340, Val 0.6898/0.5313\n",
      "MLP 5: Train 0.6879/0.5357, Val 0.6894/0.5319\n",
      "MLP 6: Train 0.6874/0.5367, Val 0.6895/0.5312\n",
      "MLP 7: Train 0.6869/0.5366, Val 0.6894/0.5328\n",
      "MLP 8: Train 0.6863/0.5387, Val 0.6891/0.5312\n",
      "MLP 9: Train 0.6860/0.5405, Val 0.6894/0.5335\n",
      "MLP 10: Train 0.6857/0.5396, Val 0.6902/0.5355\n",
      "MLP 11: Train 0.6851/0.5408, Val 0.6888/0.5347\n",
      "MLP 12: Train 0.6846/0.5422, Val 0.6895/0.5339\n",
      "MLP 13: Train 0.6842/0.5445, Val 0.6888/0.5368\n",
      "MLP 14: Train 0.6834/0.5450, Val 0.6889/0.5339\n",
      "MLP 15: Train 0.6832/0.5461, Val 0.6885/0.5393\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mlp=MLPClassifier(WINDOW_SIZE).to(device)\n",
    "crit=nn.BCELoss()\n",
    "opt=torch.optim.Adam(mlp.parameters(),lr=LR)\n",
    "best=None; best_val=float(\"inf\")\n",
    "\n",
    "for epoch in range(1,EPOCHS_MLP+1):\n",
    "    tr_l,tr_a=train_epoch(mlp,train_loader,crit,opt)\n",
    "    va_l,va_a,_,_=eval_epoch(mlp,val_loader,crit)\n",
    "    print(f\"MLP {epoch}: Train {tr_l:.4f}/{tr_a:.4f}, Val {va_l:.4f}/{va_a:.4f}\")\n",
    "    if va_l<best_val: best_val=va_l; best=mlp.state_dict()\n",
    "\n",
    "mlp.load_state_dict(best)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52d1d456",
   "metadata": {},
   "source": [
    "## 10. Test MLP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "d8fc4662",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MLP Test Accuracy: 0.526327909118821\n"
     ]
    }
   ],
   "source": [
    "tl,ta,preds,labels=eval_epoch(mlp,test_loader,crit)\n",
    "print(\"MLP Test Accuracy:\", ta)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22fb5f79",
   "metadata": {},
   "source": [
    "## 11. Prepare LSTM Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "a14a63fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_seq=X_train.reshape(-1,WINDOW_SIZE,1)\n",
    "X_val_seq=X_val.reshape(-1,WINDOW_SIZE,1)\n",
    "X_test_seq=X_test.reshape(-1,WINDOW_SIZE,1)\n",
    "\n",
    "train_loader_seq=DataLoader(TensorDataset(torch.tensor(X_train_seq),y_train_t),batch_size=BATCH_SIZE,shuffle=True)\n",
    "val_loader_seq=DataLoader(TensorDataset(torch.tensor(X_val_seq),y_val_t),batch_size=BATCH_SIZE)\n",
    "test_loader_seq=DataLoader(TensorDataset(torch.tensor(X_test_seq),y_test_t),batch_size=BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c801d8e",
   "metadata": {},
   "source": [
    "## 12. Train LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "ed0993b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LSTM 1: Train 0.6920/0.5252, Val 0.6930/0.5230\n",
      "LSTM 2: Train 0.6918/0.5263, Val 0.6920/0.5230\n",
      "LSTM 3: Train 0.6917/0.5264, Val 0.6918/0.5233\n",
      "LSTM 4: Train 0.6916/0.5283, Val 0.6915/0.5246\n",
      "LSTM 5: Train 0.6913/0.5294, Val 0.6915/0.5249\n",
      "LSTM 6: Train 0.6913/0.5298, Val 0.6913/0.5283\n",
      "LSTM 7: Train 0.6912/0.5301, Val 0.6910/0.5301\n",
      "LSTM 8: Train 0.6911/0.5294, Val 0.6910/0.5284\n",
      "LSTM 9: Train 0.6906/0.5307, Val 0.6908/0.5275\n",
      "LSTM 10: Train 0.6898/0.5306, Val 0.6901/0.5292\n",
      "LSTM 11: Train 0.6896/0.5294, Val 0.6899/0.5262\n",
      "LSTM 12: Train 0.6900/0.5302, Val 0.6906/0.5270\n",
      "LSTM 13: Train 0.6893/0.5325, Val 0.6898/0.5282\n",
      "LSTM 14: Train 0.6890/0.5317, Val 0.6896/0.5288\n",
      "LSTM 15: Train 0.6889/0.5318, Val 0.6901/0.5276\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lstm=LSTMClassifier(feature_dim=1).to(device)\n",
    "opt2=torch.optim.Adam(lstm.parameters(),lr=LR)\n",
    "best_l=None; best_val_l=float(\"inf\")\n",
    "\n",
    "for epoch in range(1,EPOCHS_LSTM+1):\n",
    "    tr_l,tr_a=train_epoch(lstm,train_loader_seq,crit,opt2)\n",
    "    va_l,va_a,_,_=eval_epoch(lstm,val_loader_seq,crit)\n",
    "    print(f\"LSTM {epoch}: Train {tr_l:.4f}/{tr_a:.4f}, Val {va_l:.4f}/{va_a:.4f}\")\n",
    "    if va_l<best_val_l: best_val_l=va_l; best_l=lstm.state_dict()\n",
    "\n",
    "lstm.load_state_dict(best_l)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a6944a3",
   "metadata": {},
   "source": [
    "## 13. Test LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "b77715cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LSTM Test Accuracy: 0.5181148295977894\n"
     ]
    }
   ],
   "source": [
    "tl,ta,preds,labels=eval_epoch(lstm,test_loader_seq,crit)\n",
    "print(\"LSTM Test Accuracy:\", ta)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc86eea2",
   "metadata": {},
   "source": [
    "## 14. Save Weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "454db72a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved mlp_weights.pth and lstm_weights.pth\n"
     ]
    }
   ],
   "source": [
    "os.makedirs(\"../models/saved_weights\",exist_ok=True)\n",
    "torch.save(mlp.state_dict(),\"../models/saved_weights/mlp_weights.pth\")\n",
    "torch.save(lstm.state_dict(),\"../models/saved_weights/lstm_weights.pth\")\n",
    "print(\"Saved mlp_weights.pth and lstm_weights.pth\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
